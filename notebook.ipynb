{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational data assimilation with deep prior \n",
    "\n",
    "## Context\n",
    "### Purpose\n",
    "Solve data assimilation problems with implicit regularization with deep prior.\n",
    "\n",
    "### Description\n",
    "Deep image prior, a neural network with proven results in standard inverse problems, is used to determine the state of a physical system. It is a fully unsupervised model which acts as implicit regularization in the variational data assimilation metthod. The algorithm is demonstrated with a shallow-water toy model and the simulated observations are compared with variational assimilation without regularization, with Tikhonov regularization and with deep prior.\n",
    "\n",
    "### Highlights\n",
    "* Fetch the modelling codebase from the GitHub repo provided with the paper.\n",
    "* Run the main Python script to generate sample observations from a shallow-water model and variational assimilation solutions.\n",
    "* Recreate visualizations from the paper.\n",
    "* Compare assimilation scores and smoothness statistics between the different models.\n",
    "\n",
    "### Contributions\n",
    "\n",
    "#### Notebook\n",
    "* Mukulika Pahari (author), University of Mumbai, [@Mukulikaa](https://github.com/Mukulikaa)\n",
    "* Rutika Bhoir (author), University of Mumbai, [@Rutika-16](https://github.com/Rutika-16)\n",
    "\n",
    "#### Modelling codebase\n",
    "* Arthur Filoche (author), Sorbonne Université, [@ArFiloche](https://github.com/ArFiloche)\n",
    "\n",
    "#### Modelling publications\n",
    "* Filoche, A., Béréziat, D., & Charantonis, A. (2023). Deep prior in variational assimilation to estimate an ocean circulation without explicit regularization. <i>Environmental Data Science,</i> <i>2</i>, E2. doi:10.1017/eds.2022.31\n",
    "\n",
    "### Source code\n",
    "The authors of the notebook acknowledge the original creator for providing public code available at [Deepprior4DVar_CI22](https://github.com/ArFiloche/Deepprior4DVar_CI22)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clone the paper's GitHub repository\n",
    "\n",
    "The cloned repository is moved to the current directory to easily import the required Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone -q https://github.com/ArFiloche/Deepprior4DVar_CI22 \n",
    "!mv -v Deepprior4DVar_CI22/* .\n",
    "!rm -rf Deepprior4DVar_CI22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/arthur_lip6/Projets_info/Deep_prior_CI2022')\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import dynamics\n",
    "import utils\n",
    "\n",
    "import _4DVar\n",
    "import _DeepPrior4DVar\n",
    "\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set project structure\n",
    "\n",
    "The following directory structure is the same as given in the project repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "root_dir = 'data/generated/'\n",
    "save_dir = 'data/estimated/'\n",
    "\n",
    "if os.path.exists('data'):\n",
    "    shutil.rmtree('data')\n",
    "    \n",
    "os.makedirs(root_dir)\n",
    "os.makedirs('data/results/')\n",
    "os.makedirs(save_dir+'4DVar/')\n",
    "os.makedirs(save_dir+'4DVar_reg/')\n",
    "os.makedirs(save_dir+'4DVar_deep/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data and run assimilations\n",
    "\n",
    "The  `Deepprior4DVar_CI22` repo has the following main modules:\n",
    "* `dynamics`: For simulating the shallow-water model.\n",
    "* `_4DVar`: For assimilation with and without regularization.\n",
    "* `_DeepPrior4DVar`: For assimilation with deep prior.\n",
    "\n",
    "The repo has a script- `main.py`, to perform all the steps required to reproduce the paper. In this notebook, this script has been run with a smaller sample size to reproduce the results. The repo also contains Jupyter notebooks for demonstration in the `notebooks_demo` directory.\n",
    "\n",
    "The first step is to generate observations from a shallow-water model initialized with initial state variables. Keeping in mind the computational limitations, the sample size has been reduced to 20 from 100, as taken in the original script. The output is stored in `data/generated`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>Note: </b> You can change to the original value of n_sample=100 according to the availability of GPU resources </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n_sample=20\n",
    "dx = utils.data_generator.dx\n",
    "dy = utils.data_generator.dy\n",
    "dynamics_obj=dynamics.SW(dx,dy)\n",
    "generator=utils.DataGenerator(dynamics_obj,T=10,subsample=3,sigma=0.05)\n",
    "generator.dataset(n_sample, root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the script is run as is. The next steps include:\n",
    "* extracting observations from the simulated model,\n",
    "* performing 4D variational assimilation with and without regularization,\n",
    "* performing deep prior 4D variational assimilation,\n",
    "* computing performance metrics,\n",
    "  * Endpoint Error - EPE\n",
    "  * Angular Error -AE\n",
    "  * ||grad|| - $\\|| \\nabla\\mathbf{w}_0\\||_2$\n",
    "  * ||div|| - $\\|| \\nabla . \\mathbf{w}_0\\||_2$\n",
    "  * ||lap|| - $\\||\\Delta \\mathbf{w}_0\\||_2$\n",
    "* storing computed metrics in a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results=np.zeros((n_sample,4,5)) # EPE, AE, ||grad||, ||div||, ||lap||\n",
    "\n",
    "for i in range(n_sample):\n",
    "    print(i)\n",
    "    \n",
    "    #load data\n",
    "    initial_condition=np.load(root_dir+'initial_conditions/'+'{0:04}'.format(int(i))+'.npy')\n",
    "    w0_truth=torch.Tensor(initial_condition[1:,:,:])\n",
    "    \n",
    "    # results\n",
    "    results[i,0,0]=utils.EPE(w0_truth, w0_truth) #0\n",
    "    results[i,0,1]=utils.Angular_error(w0_truth, w0_truth) #0\n",
    "    results[i,0,2]=utils.norm_gradw(w0_truth)\n",
    "    results[i,0,3]=utils.norm_divw(w0_truth)\n",
    "    results[i,0,4]=utils.norm_lapw(w0_truth)\n",
    "    \n",
    "    Obs=np.load(root_dir+'Obs/'+'{0:04}'.format(int(i))+'.npy')\n",
    "    Obs=torch.Tensor(Obs)\n",
    "    \n",
    "    Rm1=torch.ones(Obs.shape)*(Obs!=0)\n",
    "    Rm1=torch.Tensor(Rm1)\n",
    "    \n",
    "    ## 4D-Var #####\n",
    "    assim = _4DVar.strong_4DVar(dynamics=dynamics_obj,\n",
    "                         optimizer=optim.LBFGS([torch.zeros(0)],lr=0.75, max_iter=250))\n",
    "    assim.fit(Obs=Obs,Rm1=Rm1)\n",
    "    \n",
    "    w0_4dvar= assim.initial_condition[1:,:,:]\n",
    "    np.save(save_dir+'4DVar/'+'{0:04}'.format(int(i))+'.npy', w0_4dvar)\n",
    "    \n",
    "    # results\n",
    "    results[i,1,0]=utils.EPE(w0_truth, w0_4dvar)\n",
    "    results[i,1,1]=utils.Angular_error(w0_truth, w0_4dvar)\n",
    "    results[i,1,2]=utils.norm_gradw(w0_4dvar)\n",
    "    results[i,1,3]=utils.norm_divw(w0_4dvar)\n",
    "    results[i,1,4]=utils.norm_lapw(w0_4dvar)\n",
    "    \n",
    "    ## Thikonov 4D-Var #####\n",
    "    smoothreg= _4DVar.smooth_regul(alpha=5e3, beta=5e2,dx=dx,dy=dy)\n",
    "    assim = _4DVar.strong_4DVar(dynamics=dynamics_obj, regul=smoothreg,\n",
    "                         optimizer=optim.LBFGS([torch.zeros(0)],lr=0.75, max_iter=250))\n",
    "    assim.fit(Obs=Obs,Rm1=Rm1)\n",
    "    \n",
    "    w0_4dvar_reg=assim.initial_condition[1:,:,:]\n",
    "    np.save(save_dir+'4DVar_reg/'+'{0:04}'.format(int(i))+'.npy', w0_4dvar_reg)\n",
    "    \n",
    "    # results\n",
    "    results[i,2,0]=utils.EPE(w0_truth, w0_4dvar_reg)\n",
    "    results[i,2,1]=utils.Angular_error(w0_truth, w0_4dvar_reg)\n",
    "    results[i,2,2]=utils.norm_gradw(w0_4dvar_reg)\n",
    "    results[i,2,3]=utils.norm_divw(w0_4dvar_reg)\n",
    "    results[i,2,4]=utils.norm_lapw(w0_4dvar_reg)\n",
    "    \n",
    "    ## Deep prior 4D-Var #####\n",
    "    netG = _DeepPrior4DVar.Generator()\n",
    "    netG.apply(_DeepPrior4DVar.weights_init)\n",
    "    \n",
    "    noise = torch.randn(netG.nz, 1, 1)\n",
    "    \n",
    "    assim=_DeepPrior4DVar.deeprior_strong_4DVar(generator=netG, dynamics=dynamics_obj,\n",
    "                               lr = 0.002, beta1 = 0.5, n_epoch=2000)\n",
    "    assim.fit(noise, Obs, Rm1)\n",
    "    \n",
    "    w0_4dvar_deep=assim.initial_condition[1:,:,:]\n",
    "    np.save(save_dir+'4DVar_deep/'+'{0:04}'.format(int(i))+'.npy', w0_4dvar_deep)\n",
    "    \n",
    "    # results\n",
    "    results[i,3,0]=utils.EPE(w0_truth, w0_4dvar_deep)\n",
    "    results[i,3,1]=utils.Angular_error(w0_truth, w0_4dvar_deep)\n",
    "    results[i,3,2]=utils.norm_gradw(w0_4dvar_deep)\n",
    "    results[i,3,3]=utils.norm_divw(w0_4dvar_deep)\n",
    "    results[i,3,4]=utils.norm_lapw(w0_4dvar_deep)\n",
    "    \n",
    "    np.save('./data/results/main.npy',results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "The data generated from the script is loaded into variables for visualization. The plots are made with the scripts provided in `utils`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "root_dir='data/generated/'\n",
    "\n",
    "initial_condition=np.load(root_dir+'initial_conditions/'+\n",
    "                          '{0:04}'.format(int(i))+'.npy')\n",
    "Obs=np.load(root_dir+'Obs/'\n",
    "                          +'{0:04}'.format(int(i))+'.npy')\n",
    "\n",
    "results=np.load('data/results/main.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Initial conditions\n",
    "\n",
    "The plot below shows the evolution of the simluated system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = torch.Tensor(initial_condition)\n",
    "plt.figure(figsize=(20,4))\n",
    "for t in range(T):\n",
    "        \n",
    "    plt.subplot(2,T,t+1)\n",
    "    plt.title('$\\eta_{'+str(t)+'}$',fontsize=17)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "\n",
    "    plt.imshow(X[0,:,:])\n",
    "    plt.subplot(2,T,T+t+1)\n",
    "    plot_w(X[1,:,:],X[2,:,:],quiver=True,title='w_'+str(t),q_scale=2.5)\n",
    "    plt.title('$w_{'+str(t)+'}$',fontsize=17)\n",
    "    \n",
    "    X=dynamics.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations with noise\n",
    "\n",
    "The plot below shows the observations extracted from the simulated system and infused with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T=10    # Assimilation window size\n",
    "subsample=3    # Subsampling frequency\n",
    " \n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "for t in range(T):\n",
    "        \n",
    "    plt.subplot(1,T,t+1)\n",
    "    plt.title('$Y_{'+str(t)+'}$',fontsize=17)\n",
    "    if t%subsample==0:\n",
    "        plt.imshow(Obs[t,0,:])\n",
    "    else :\n",
    "        plt.imshow(float('Nan')*Obs[t,0,:])\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "The following plots represent the dynamical state of the system through the different assimilation approaches and the observed state. It is a reconstruction of [Figure 4](https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230110163855547-0883:S2634460222000310:S2634460222000310_fig4.png) in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = 'data/estimated/'\n",
    "\n",
    "w0_truth=initial_condition[1:,:,:]\n",
    "\n",
    "w0_4dvar=np.load(save_dir+'4DVar/'+'{0:04}'.format(int(i))+'.npy')\n",
    "w0_4dvar_reg=np.load(save_dir+'4DVar_reg/'+'{0:04}'.format(int(i))+'.npy')\n",
    "w0_4dvar_deep=np.load(save_dir+'4DVar_deep/'+'{0:04}'.format(int(i))+'.npy')\n",
    "\n",
    "u0_truth=torch.Tensor(w0_truth[0,:,:])\n",
    "v0_truth=torch.Tensor(w0_truth[1,:,:])\n",
    "    \n",
    "u0_4dvar=torch.Tensor(w0_4dvar[0,:,:])\n",
    "v0_4dvar=torch.Tensor(w0_4dvar[1,:,:])\n",
    "\n",
    "u0_4dvar_reg=torch.Tensor(w0_4dvar_reg[0,:,:])\n",
    "v0_4dvar_reg=torch.Tensor(w0_4dvar_reg[1,:,:])\n",
    "\n",
    "u0_4dvar_deep=torch.Tensor(w0_4dvar_deep[0,:,:])\n",
    "v0_4dvar_deep=torch.Tensor(w0_4dvar_deep[1,:,:])\n",
    "\n",
    "normalization = True\n",
    "quiver = True\n",
    "q_alpha = 0.5\n",
    "q_scale =2.5\n",
    "sub=4\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "    \n",
    "plt.subplot(1,4,1)\n",
    "plot_w(u0_4dvar,v0_4dvar,\n",
    "       normalization=normalization,\n",
    "       quiver=quiver, q_alpha=q_alpha,q_scale=q_scale,\n",
    "       title = '4D-Var')\n",
    "plt.title('4D-Var',fontsize=20)\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plot_w(u0_4dvar_deep,v0_4dvar_deep,\n",
    "       normalization=normalization,\n",
    "       quiver=quiver, q_alpha=q_alpha,q_scale=q_scale,\n",
    "       title = 'Deep prior 4D-Var')\n",
    "plt.title('Deep prior 4D-Var',fontsize=20)\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plot_w(u0_4dvar_reg,v0_4dvar_reg,\n",
    "       normalization=normalization,\n",
    "       quiver=quiver, q_alpha=q_alpha,q_scale=q_scale,\n",
    "       title = '4D-Var + Thikhonov')\n",
    "plt.title('\"Thikhonov\" 4D-Var ',fontsize=20)\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plot_w(u0_truth,v0_truth,\n",
    "       normalization=normalization,\n",
    "       quiver=quiver, q_alpha=q_alpha,q_scale=q_scale,\n",
    "       title = '')\n",
    "plt.title('Ground truth',fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "The following plots compare the different algorithms with respect to the five metrics as mentioned in the paper:\n",
    "* Endpoint error\n",
    "* Angular error\n",
    "* Smoothness statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins=10\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "titles=[\"Endpoint error\",\"Angular error\"]\n",
    "for i in range(0,2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    \n",
    "    plt.hist([results[:,j,i] for j in range(1, 4)], \n",
    "             bins, label=['4D-Var','\"Thikonov\" 4D-Var', 'Deep prior 4D-Var'])\n",
    "    if i == 1:\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.title(titles[i-1],fontsize=20)\n",
    "    plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins=15\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "titles=[r\"$\\|| \\nabla\\mathbf{w}_0\\||_2$\",r\"$\\|| \\nabla . \\mathbf{w}_0\\||_2$\",'$\\||\\Delta \\mathbf{w}_0\\||_2$']\n",
    "for i in range(2,results.shape[2]):\n",
    "    plt.subplot(1,3,i-1)\n",
    "    \n",
    "    plt.hist([results[:,j,i] for j in range(4)], \n",
    "             bins, label=['Ground truth', '4D-Var','\"Thikonov\" 4D-Var', 'Deep prior 4D-Var'])\n",
    "    if i == 4:\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.title(titles[i-2],fontsize=20)\n",
    "    plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table is a direct comparison between the metrics. They are within the limits of the error rates as mentioned in [Table 1](https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230110163855547-0883:S2634460222000310:S2634460222000310_tab1.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_format = \"grid\"\n",
    "table = [\n",
    "    [\"Metrics\", \"Ground truth\", \"4D-Var\", \"'Thikonov' 4D-Var\", \"Deep prior 4D-Var\"],\n",
    "    [\"EPE\", results.mean(axis=0)[0, 0], results.mean(axis=0)[1, 0], results.mean(axis=0)[2, 0], results.mean(axis=0)[3, 0]],\n",
    "    [\"Angular error\", results.mean(axis=0)[0, 1], results.mean(axis=0)[1, 1], results.mean(axis=0)[2, 1], results.mean(axis=0)[3, 1]],\n",
    "    [\"||grad||\", results.mean(axis=0)[0, 2], results.mean(axis=0)[1, 2], results.mean(axis=0)[2, 2], results.mean(axis=0)[3, 2]],\n",
    "    [\"||div||\", results.mean(axis=0)[0, 3], results.mean(axis=0)[1, 3], results.mean(axis=0)[2, 3], results.mean(axis=0)[3, 3]],\n",
    "    [\"||lap||\", results.mean(axis=0)[0, 4], results.mean(axis=0)[1, 4], results.mean(axis=0)[2, 4], results.mean(axis=0)[3, 4]],\n",
    "]\n",
    "\n",
    "\n",
    "formatted_table = tabulate(table, headers=\"firstrow\", tablefmt=table_format)\n",
    "\n",
    "print(formatted_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges and improvements\n",
    "\n",
    "* While most cloud-based notebook servers come with pre-installed packages, it will be helpful to include an environment file in the codebase to aid local runs.\n",
    "* The codebase is modularized and easy to understand but a brief outline in the Readme file would be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The results in the paper \"Deep prior in variational assimilation to estimate an ocean circulation without explicit regularization\" can be correctly reproduced with the help of the materials provided with the paper. \n",
    "* This paper encourages the use of deep learning techniques in traditional inverse problems which are a basis for many geoscience modelling experiments.\n",
    "* PyTorch is used for running the assimilation models and NumPy is used to store the results.\n",
    "* Matplotlib is used for all visualizations.\n",
    "* Possible improvements include add an environment file and a comprehensive README file to support the modelling codebase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information\n",
    "**Dataset**: All data is generated at runtime.\n",
    "\n",
    "**Codebase**: https://github.com/ArFiloche/Deepprior4DVar_CI22 - commit 83961da on the main branch.\n",
    "\n",
    "**License**: The code in this notebook is licensed under the MIT License. The Environmental Data Science book is licensed under the Creative Commons by Attribution 4.0 license. See further details [here](https://github.com/alan-turing-institute/environmental-ds-book/blob/master/LICENSE.md).\n",
    "\n",
    "**Contact**: If you have any suggestion or report an issue with this notebook, feel free to [create an issue](https://github.com/alan-turing-institute/environmental-ds-book/issues/new/choose) or send a direct message to [environmental.ds.book@gmail.com](mailto:environmental.ds.book@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "print(f'Last tested: {date.today()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
